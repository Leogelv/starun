import { NextRequest, NextResponse } from 'next/server';

const WHISPER_ENDPOINT = 'https://primary-production-ee24.up.railway.app/webhook/whispa';

export async function POST(request: NextRequest) {
  try {
    console.log('=== Speech API POST called ===');
    console.log('üèóÔ∏è Proxying to external whisper endpoint');
    
    // Get the form data from the request
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      console.error('‚ùå No audio file provided');
      return NextResponse.json({ 
        error: 'No audio file provided',
        success: false,
        text: '–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∑–∞–ø—Ä–æ—Å–µ'
      }, { status: 400 });
    }

    console.log('‚úÖ Received audio file:', {
      name: audioFile.name,
      type: audioFile.type,
      size: audioFile.size
    });

    // Validate file size (25MB limit)
    const maxSize = 25 * 1024 * 1024;
    if (audioFile.size > maxSize) {
      console.error('‚ùå File too large:', audioFile.size);
      return NextResponse.json({ 
        error: 'File too large',
        success: false,
        text: '–ê—É–¥–∏–æ —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 25MB'
      }, { status: 400 });
    }

    // Create new FormData for the external request
    const externalFormData = new FormData();
    
    // Convert File to Blob for the external request
    const arrayBuffer = await audioFile.arrayBuffer();
    const blob = new Blob([arrayBuffer], { type: audioFile.type });
    
    // Add the file to FormData with the expected field name
    externalFormData.append('file', blob, audioFile.name);

    console.log('üì§ Sending to external Whisper API...');
    
    // Make request to external endpoint
    const response = await fetch(WHISPER_ENDPOINT, {
      method: 'POST',
      body: externalFormData,
      headers: {
        'Accept': 'application/json',
      },
    });

    console.log('üì• External API response:', {
      status: response.status,
      statusText: response.statusText,
      contentType: response.headers.get('content-type')
    });

    // Get the response text
    const responseText = await response.text();
    console.log('üìù Transcription result:', responseText);

    if (!response.ok) {
      console.error('‚ùå External API error:', response.status, responseText);
      return NextResponse.json({ 
        text: '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.',
        success: false,
        error: responseText
      }, { status: response.status });
    }

    // Check if response is empty or just whitespace
    if (!responseText || responseText.trim() === '') {
      return NextResponse.json({ 
        text: '–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –≥—Ä–æ–º—á–µ –∏ —á–µ—Ç—á–µ.',
        success: false
      });
    }

    // Return the transcribed text
    return NextResponse.json({ 
      text: responseText.trim(),
      success: true
    });

  } catch (error: unknown) {
    console.error('Speech API error:', error);
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    
    return NextResponse.json(
      { 
        error: 'Failed to transcribe audio', 
        details: errorMessage,
        text: '–û–±—â–∞—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.',
        success: false
      },
      { status: 500 }
    );
  }
} 